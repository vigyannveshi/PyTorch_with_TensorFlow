{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64aef951",
   "metadata": {},
   "source": [
    "**23. Transfer Learning in PyTorch**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc3a05b",
   "metadata": {},
   "source": [
    "* Transfer Learning is a ML technique where a model trained on one task is reused (partially or fully) for a different but related task. Instead of training a model from scratch, which can be computationally expensive and require large datasets, transfer learning leverages knowledge from a pre-trained model to improve learning efficiency and performance.\n",
    "* Working of Transfer Learning:\n",
    "  1. Pretraining on a Large Dataset\n",
    "    * A model is first trained on a large dataset (e.g. ImageNet for images, GPT for text)\n",
    "    * The model learns the general features, such as edges and shapes in images or syntax and semantics in text.\n",
    "  2. Fine-tuning for a new task\n",
    "    * The pre-trained model is then adapted to a new, often smaller, dataset.\n",
    "    * Some layers may be frozen (not updated), while others are fine-tuned for the specific task.\n",
    "* Steps:\n",
    "  * import model (to be used for transfer-learning)\n",
    "  * detach the classifier\n",
    "  * attach custom/our classifier\n",
    "  * freeze feature extraction layer\n",
    "  * train the model\n",
    "* We will be using VGG16 model, but it requires a little pre-processing:\n",
    "  * reshape: 784 --> (28,28)\n",
    "  * dtype = np.uint8\n",
    "  * convert from 1D to 3D: (28,28) --> (3,28,28) \n",
    "  * convert to PIL image\n",
    "  * resize from (3,28,28) to (3,256,256) using InterpolationMode.BILINEAR\n",
    "  * center-crop (3,224,224)\n",
    "  * convert to pytorch tensor and scale between 0 to 1\n",
    "  * normalize using mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7940c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import torch as tr\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "# import plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_inline\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n",
    "\n",
    "# set random seeds for reproducibility\n",
    "random_seed = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551ec8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = tr.device('cuda' if tr.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4310235f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/fmnist_small.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0958b145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformations\n",
    "from torchvision import transforms\n",
    "custom_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((256,256),interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "        transforms.CenterCrop((224,224)),\n",
    "        transforms.ToTensor(), # transforms to PyTorch tensor and scales all values between 0 and 1,\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225]) \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4477a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.arange(1,5).reshape(2,2)\n",
    "np.stack([arr]*3).shape,np.stack([arr]*3,axis=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f1e519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting data as numpy arrays\n",
    "X = df.drop(columns=['label']).to_numpy()\n",
    "y = df['label'].to_numpy()\n",
    "\n",
    "class_labels =  [\"T-shirt/top\",\n",
    "                \"Trouser\",\n",
    "                \"Pullover\",\n",
    "                \"Dress\",\n",
    "                \"Coat\",\n",
    "                \"Sandal\",\n",
    "                \"Shirt\",\n",
    "                \"Sneaker\",\n",
    "                \"Bag\",\n",
    "                \"Ankle boot\"]\n",
    "\n",
    "# perform train-test split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "from PIL import Image\n",
    "# creating dataset class\n",
    "class FMNIST_DATASET(Dataset):\n",
    "    def __init__(self,X,y,transform):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # 1. resize to (28,28)\n",
    "        img = self.X[index].reshape(28,28)\n",
    "\n",
    "        # 2. change datatype to np.uint8\n",
    "        img = img.astype(np.uint8)\n",
    "\n",
    "        # change 1 channel to 3 channel -> height, width, channels\n",
    "        img = np.stack([img]*3, axis = -1)\n",
    "\n",
    "        # 4. convert to PIL image\n",
    "        img = Image.fromarray(img)\n",
    "\n",
    "        # 5. apply transformations\n",
    "        return self.transform(img),tr.tensor(self.y[index],dtype=tr.long)\n",
    "\n",
    "    \n",
    "train_dataset = FMNIST_DATASET(X_train,y_train,custom_transform)\n",
    "test_dataset = FMNIST_DATASET(X_test,y_test,custom_transform)\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "train_loader = DataLoader(train_dataset,batch_size= BATCH_SIZE, shuffle = True)\n",
    "test_loader = DataLoader(test_dataset,batch_size= BATCH_SIZE, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9186b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(2,4,figsize = (8,4))\n",
    "\n",
    "images,labels = next(iter(train_loader))\n",
    "\n",
    "\n",
    "for i,ax in enumerate(axes.flat):\n",
    "    ax.imshow(images[i][0],cmap = 'binary')\n",
    "    ax.axis('off')\n",
    "    ax.set_title(f'{class_labels[labels[i]]}')\n",
    "\n",
    "plt.tight_layout(rect=[0,0,1,0.96])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaaafaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using a pre-trained model\n",
    "import torchvision.models as models\n",
    "vgg16 = models.vgg16(pretrained = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7be6950",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in vgg16.features.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5445fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FMNIST_NET(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # feature extractor \n",
    "        self.features = vgg16.features\n",
    "\n",
    "        # classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features = 25088, out_features = 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "\n",
    "            nn.Linear(in_features = 64, out_features = 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "\n",
    "            nn.Linear(in_features = 32, out_features = 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# from torchinfo import summary\n",
    "# demo_model = FMNIST_NET()\n",
    "# summary(demo_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529310ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate and epochs\n",
    "lr = 1e-3\n",
    "epochs = 5\n",
    "\n",
    "# instantiating the model\n",
    "fnet = FMNIST_NET()\n",
    "\n",
    "# loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer\n",
    "optimizer = tr.optim.Adam(fnet.classifier.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171877f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fnet = fnet.to(device) # move the model to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3d8e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "for epochi in range(epochs):\n",
    "    fnet.train()\n",
    "    batch_loss = []\n",
    "    for X_batch,y_batch in train_loader:\n",
    "        # moving data to device (GPU)\n",
    "        X_batch,y_batch = X_batch.to(device),y_batch.to(device)\n",
    "        \n",
    "        # forward pass\n",
    "        y_pred = fnet(X_batch)\n",
    "\n",
    "        # loss calculation\n",
    "        loss = loss_fn(y_pred,y_batch)\n",
    "        batch_loss.append(loss.item())\n",
    "\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # upgrade parameters\n",
    "        optimizer.step()\n",
    "\n",
    "    mean_batch_loss = np.mean(batch_loss)\n",
    "    \n",
    "    # perform validation\n",
    "    fnet.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with tr.no_grad(): # disable gradient tracking\n",
    "        for X_val,y_val in test_loader:\n",
    "            # moving data to device(GPU)\n",
    "            X_val,y_val = X_val.to(device),y_val.to(device)\n",
    "            \n",
    "            y_pred = fnet(X_val)\n",
    "            preds = tr.argmax(y_pred,dim=1)\n",
    "            val_correct += (preds == y_val).sum().item()\n",
    "            val_total += y_val.size(0)\n",
    "    val_acc = (val_correct / val_total)*100\n",
    "\n",
    "    print(f'Epoch: {epochi+1}, Loss: {mean_batch_loss}, Val Accuracy:{val_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e9dfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model,test_loader):\n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "\n",
    "    device = tr.device('cuda' if tr.cuda.is_available() else 'cpu')\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    with tr.no_grad():\n",
    "        for X_batch,y_batch in test_loader:\n",
    "            # moving data to device(GPU)\n",
    "            X_batch,y_batch = X_batch.to(device),y_batch.to(device)\n",
    "\n",
    "            y_pred = model(X_batch)\n",
    "            preds = tr.argmax(y_pred, dim = 1)\n",
    "            correct_preds+=(preds == y_batch).sum().item()\n",
    "            total_preds += y_batch.size(0)\n",
    "        accuracy = (correct_preds/total_preds)\n",
    "        return accuracy\n",
    "    \n",
    "evaluate_model(fnet,test_loader) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
